{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b24837",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Auditing a CNN trained on CIFAR100 using the Reference Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed55c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will see:\n",
    "\n",
    "- How to specify the dataset and model for Privacy Meter\n",
    "- How to audit a Tensorflow model\n",
    "- How to use the `ReferenceMetric` to evaluate membership leakage using loss values from reference models\n",
    "- How to visualize the audit result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfc8ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e571ad5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee7e3da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from privacy_meter.audit import Audit\n",
    "from privacy_meter.audit_report import ROCCurveReport, SignalHistogramReport\n",
    "from privacy_meter.constants import InferenceGame\n",
    "from privacy_meter.dataset import Dataset\n",
    "from privacy_meter.information_source import InformationSource\n",
    "from privacy_meter.metric import ReferenceMetric\n",
    "from privacy_meter.model import TensorflowModel\n",
    "from privacy_meter.information_source_signal import ModelLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7802f1e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d12b56",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setting seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6f914c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee72a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c787a5d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for training the target and reference models\n",
    "num_points_per_train_split = 5000\n",
    "num_points_per_test_split = 1000\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optim_fn = 'adam'\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "regularizer_penalty = 0.01\n",
    "regularizer = tf.keras.regularizers.l2(l=regularizer_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90266375",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for the reference metric\n",
    "num_reference_models = 10\n",
    "fpr_tolerance_list = [\n",
    "    0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af2c28",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae07f3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use the CIFAR100 dataset for this tutorial. As Tensorflow already has the data loading code for CIFAR100, we just need to add our pre-processing code on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35272cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_cifar100_dataset():\n",
    "    input_shape, num_classes = (32, 32, 3), 100\n",
    "\n",
    "    # split the data between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "    # scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "    # convert labels into one hot vectors\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, input_shape, num_classes\n",
    "\n",
    "x_train_all, y_train_all, x_test_all, y_test_all, input_shape, num_classes = preprocess_cifar100_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d327057a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_all.shape, x_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f88bf5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "CIFAR100 comes with the predetermined train and test partitions. We further split the train partition into more sets - 'train' and 'reference' for the audit. \n",
    "\n",
    "We will have the following sets at the end of this partitioning:\n",
    "\n",
    "- The 'train' set will be used to train the target model. It will be used as the 'member' set for the audit.\n",
    "- The 'test' set will be used as the 'non-member' set for the audit.\n",
    "- The 'reference' set will be used later as the pool of data to train the reference models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40a032",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We wrap the sets into a `Dataset` object, which takes in the following arguments:\n",
    "\n",
    "- `data_dict` contains the actual dataset, in the form of a 2D dictionary. The first key corresponds to the split name (here we have two: \"train\" and \"test\"), and the second key to the feature name (here we also have two: \"x\" and \"y\").\n",
    "- `default_input` contains the name of the feature that should be used as the models input (here \"x\").\n",
    "- `default_output` contains the name of the feature that should be used as the label / models output (here \"y\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b834918",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the target model's dataset\n",
    "dataset = Dataset(\n",
    "    data_dict={\n",
    "        'train': {'x': x_train_all, 'y': y_train_all},\n",
    "        'test': {'x': x_test_all, 'y': y_test_all}\n",
    "    },\n",
    "    default_input='x',\n",
    "    default_output='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0b1ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we use the built-in `Dataset.subdivide()` function, to split the two splits (\"train\" and \"test\") into multiple sub-datasets (one per model). The resulting sub-splits are included in the parent object (\"train000\", \"train001\", etc.) and are returned as a list of individual Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e59fedb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_list = dataset.subdivide(\n",
    "    num_splits=num_reference_models + 1,\n",
    "    delete_original=True,\n",
    "    in_place=False,\n",
    "    return_results=True,\n",
    "    method='hybrid',\n",
    "    split_size={'train': num_points_per_train_split, 'test': num_points_per_test_split}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ffdf03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "1\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "2\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "3\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "4\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "5\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "6\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "7\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "8\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "9\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n",
      "10\n",
      "================ DATASET OBJECT ================\n",
      "Splits            = ['train', 'test']\n",
      "Features          = ['x', 'y']\n",
      "Default features  = x --> y\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(datasets_list):\n",
    "    print(i)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d71b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training the target and reference models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aeb6ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the Tensorflow model to be used as the target and reference models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b3a7e6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_tensorflow_cnn_classifier(input_shape, num_classes, regularizer):\n",
    "    # TODO: change model architecture\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                                     input_shape=input_shape, kernel_regularizer=regularizer))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu',\n",
    "                                     kernel_regularizer=regularizer))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe1b46",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And we compile and train the target model using the target dataset we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce52692",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               230500    \n",
      "=================================================================\n",
      "Total params: 249,892\n",
      "Trainable params: 249,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.8005 - accuracy: 0.0208\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3950 - accuracy: 0.0400\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 4.1541 - accuracy: 0.0882\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.9368 - accuracy: 0.1222\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.7525 - accuracy: 0.1532\n",
      "Epoch 6/10\n",
      "5000/5000 - 5s - loss: 3.5882 - accuracy: 0.1896\n",
      "Epoch 7/10\n",
      "5000/5000 - 5s - loss: 3.4492 - accuracy: 0.2200\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.3623 - accuracy: 0.2368\n",
      "Epoch 9/10\n",
      "5000/5000 - 4s - loss: 3.2991 - accuracy: 0.2436\n",
      "Epoch 10/10\n",
      "5000/5000 - 6s - loss: 3.1792 - accuracy: 0.2698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cf47180f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = datasets_list[0].get_feature('train', '<default_input>')\n",
    "y = datasets_list[0].get_feature('train', '<default_output>')\n",
    "model = get_tensorflow_cnn_classifier(input_shape, num_classes, regularizer)\n",
    "model.summary()\n",
    "model.compile(optimizer=optim_fn, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(x, y, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f6760",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We wrap the target model in the `TensorflowModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a499abd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_model = TensorflowModel(model_obj=model, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c04d2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now train reference models using the respective datasets that have been constructed for the models, and wrap each one in a `TensorflowModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1669704f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training reference model 0...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 6s - loss: 4.7611 - accuracy: 0.0230\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3451 - accuracy: 0.0566\n",
      "Epoch 3/10\n",
      "5000/5000 - 5s - loss: 4.0748 - accuracy: 0.1080\n",
      "Epoch 4/10\n",
      "5000/5000 - 5s - loss: 3.8145 - accuracy: 0.1470\n",
      "Epoch 5/10\n",
      "5000/5000 - 5s - loss: 3.6468 - accuracy: 0.1802\n",
      "Epoch 6/10\n",
      "5000/5000 - 5s - loss: 3.4976 - accuracy: 0.2062\n",
      "Epoch 7/10\n",
      "5000/5000 - 5s - loss: 3.3788 - accuracy: 0.2310\n",
      "Epoch 8/10\n",
      "5000/5000 - 5s - loss: 3.2505 - accuracy: 0.2636\n",
      "Epoch 9/10\n",
      "5000/5000 - 5s - loss: 3.1680 - accuracy: 0.2692\n",
      "Epoch 10/10\n",
      "5000/5000 - 5s - loss: 3.0549 - accuracy: 0.3014\n",
      "Training reference model 1...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7522 - accuracy: 0.0234\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3331 - accuracy: 0.0518\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 4.0574 - accuracy: 0.1050\n",
      "Epoch 4/10\n",
      "5000/5000 - 5s - loss: 3.8488 - accuracy: 0.1446\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.6797 - accuracy: 0.1740\n",
      "Epoch 6/10\n",
      "5000/5000 - 4s - loss: 3.5556 - accuracy: 0.2046\n",
      "Epoch 7/10\n",
      "5000/5000 - 5s - loss: 3.4222 - accuracy: 0.2294\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.3323 - accuracy: 0.2468\n",
      "Epoch 9/10\n",
      "5000/5000 - 5s - loss: 3.2383 - accuracy: 0.2632\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 3.1686 - accuracy: 0.2854\n",
      "Training reference model 2...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7366 - accuracy: 0.0278\n",
      "Epoch 2/10\n",
      "5000/5000 - 5s - loss: 4.2717 - accuracy: 0.0724\n",
      "Epoch 3/10\n",
      "5000/5000 - 5s - loss: 3.9527 - accuracy: 0.1160\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.7358 - accuracy: 0.1608\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.5606 - accuracy: 0.1896\n",
      "Epoch 6/10\n",
      "5000/5000 - 4s - loss: 3.4344 - accuracy: 0.2178\n",
      "Epoch 7/10\n",
      "5000/5000 - 4s - loss: 3.2893 - accuracy: 0.2540\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.1921 - accuracy: 0.2750\n",
      "Epoch 9/10\n",
      "5000/5000 - 5s - loss: 3.0896 - accuracy: 0.2862\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 2.9942 - accuracy: 0.3194\n",
      "Training reference model 3...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7887 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "5000/5000 - 5s - loss: 4.3418 - accuracy: 0.0598\n",
      "Epoch 3/10\n",
      "5000/5000 - 5s - loss: 4.0716 - accuracy: 0.1022\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.8404 - accuracy: 0.1514\n",
      "Epoch 5/10\n",
      "5000/5000 - 5s - loss: 3.6848 - accuracy: 0.1710\n",
      "Epoch 6/10\n",
      "5000/5000 - 4s - loss: 3.5284 - accuracy: 0.2136\n",
      "Epoch 7/10\n",
      "5000/5000 - 5s - loss: 3.4190 - accuracy: 0.2288\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.2879 - accuracy: 0.2536\n",
      "Epoch 9/10\n",
      "5000/5000 - 5s - loss: 3.1950 - accuracy: 0.2700\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 3.1250 - accuracy: 0.2884\n",
      "Training reference model 4...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7615 - accuracy: 0.0228\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3335 - accuracy: 0.0536\n",
      "Epoch 3/10\n",
      "5000/5000 - 5s - loss: 4.0682 - accuracy: 0.0972\n",
      "Epoch 4/10\n",
      "5000/5000 - 5s - loss: 3.8651 - accuracy: 0.1342\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.7201 - accuracy: 0.1612\n",
      "Epoch 6/10\n",
      "5000/5000 - 5s - loss: 3.5859 - accuracy: 0.1818\n",
      "Epoch 7/10\n",
      "5000/5000 - 4s - loss: 3.4745 - accuracy: 0.2038\n",
      "Epoch 8/10\n",
      "5000/5000 - 5s - loss: 3.3939 - accuracy: 0.2252\n",
      "Epoch 9/10\n",
      "5000/5000 - 5s - loss: 3.2903 - accuracy: 0.2452\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 3.2058 - accuracy: 0.2630\n",
      "Training reference model 5...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7431 - accuracy: 0.0220\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3006 - accuracy: 0.0528\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 3.9872 - accuracy: 0.1228\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.7558 - accuracy: 0.1670\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.5747 - accuracy: 0.1988\n",
      "Epoch 6/10\n",
      "5000/5000 - 5s - loss: 3.4266 - accuracy: 0.2214\n",
      "Epoch 7/10\n",
      "5000/5000 - 4s - loss: 3.3164 - accuracy: 0.2518\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.2101 - accuracy: 0.2724\n",
      "Epoch 9/10\n",
      "5000/5000 - 4s - loss: 3.1110 - accuracy: 0.2880\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 3.0306 - accuracy: 0.3038\n",
      "Training reference model 6...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7281 - accuracy: 0.0274\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3069 - accuracy: 0.0608\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 4.0257 - accuracy: 0.1146\n",
      "Epoch 4/10\n",
      "5000/5000 - 5s - loss: 3.8202 - accuracy: 0.1452\n",
      "Epoch 5/10\n",
      "5000/5000 - 5s - loss: 3.6516 - accuracy: 0.1700\n",
      "Epoch 6/10\n",
      "5000/5000 - 5s - loss: 3.4912 - accuracy: 0.2106\n",
      "Epoch 7/10\n",
      "5000/5000 - 4s - loss: 3.3813 - accuracy: 0.2332\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.2588 - accuracy: 0.2566\n",
      "Epoch 9/10\n",
      "5000/5000 - 4s - loss: 3.1453 - accuracy: 0.2760\n",
      "Epoch 10/10\n",
      "5000/5000 - 5s - loss: 3.0448 - accuracy: 0.3022\n",
      "Training reference model 7...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7319 - accuracy: 0.0218\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.2932 - accuracy: 0.0602\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 4.0087 - accuracy: 0.1146\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.7961 - accuracy: 0.1498\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.6165 - accuracy: 0.1928\n",
      "Epoch 6/10\n",
      "5000/5000 - 4s - loss: 3.4769 - accuracy: 0.2080\n",
      "Epoch 7/10\n",
      "5000/5000 - 5s - loss: 3.3494 - accuracy: 0.2388\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.2425 - accuracy: 0.2608\n",
      "Epoch 9/10\n",
      "5000/5000 - 4s - loss: 3.1595 - accuracy: 0.2770\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 3.0633 - accuracy: 0.2982\n",
      "Training reference model 8...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7253 - accuracy: 0.0192\n",
      "Epoch 2/10\n",
      "5000/5000 - 4s - loss: 4.3189 - accuracy: 0.0574\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 4.0704 - accuracy: 0.0942\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.8374 - accuracy: 0.1444\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.6625 - accuracy: 0.1738\n",
      "Epoch 6/10\n",
      "5000/5000 - 4s - loss: 3.5352 - accuracy: 0.2088\n",
      "Epoch 7/10\n",
      "5000/5000 - 5s - loss: 3.4108 - accuracy: 0.2330\n",
      "Epoch 8/10\n",
      "5000/5000 - 5s - loss: 3.3257 - accuracy: 0.2388\n",
      "Epoch 9/10\n",
      "5000/5000 - 4s - loss: 3.2009 - accuracy: 0.2720\n",
      "Epoch 10/10\n",
      "5000/5000 - 4s - loss: 3.1361 - accuracy: 0.2788\n",
      "Training reference model 9...\n",
      "Train on 5000 samples\n",
      "Epoch 1/10\n",
      "5000/5000 - 5s - loss: 4.7630 - accuracy: 0.0202\n",
      "Epoch 2/10\n",
      "5000/5000 - 5s - loss: 4.2756 - accuracy: 0.0694\n",
      "Epoch 3/10\n",
      "5000/5000 - 4s - loss: 3.9564 - accuracy: 0.1238\n",
      "Epoch 4/10\n",
      "5000/5000 - 4s - loss: 3.7391 - accuracy: 0.1628\n",
      "Epoch 5/10\n",
      "5000/5000 - 4s - loss: 3.5857 - accuracy: 0.1926\n",
      "Epoch 6/10\n",
      "5000/5000 - 4s - loss: 3.4356 - accuracy: 0.2246\n",
      "Epoch 7/10\n",
      "5000/5000 - 4s - loss: 3.3409 - accuracy: 0.2422\n",
      "Epoch 8/10\n",
      "5000/5000 - 4s - loss: 3.2563 - accuracy: 0.2528\n",
      "Epoch 9/10\n",
      "5000/5000 - 4s - loss: 3.1467 - accuracy: 0.2814\n",
      "Epoch 10/10\n",
      "5000/5000 - 12s - loss: 3.0699 - accuracy: 0.2896\n"
     ]
    }
   ],
   "source": [
    "reference_models = []\n",
    "for model_idx in range(num_reference_models):\n",
    "    print(f\"Training reference model {model_idx}...\")\n",
    "    reference_model = get_tensorflow_cnn_classifier(input_shape, num_classes, regularizer)\n",
    "    reference_model.compile(optimizer=optim_fn, loss=loss_fn, metrics=['accuracy'])\n",
    "    reference_model.fit(\n",
    "        datasets_list[model_idx + 1].get_feature('train', '<default_input>'),\n",
    "        datasets_list[model_idx + 1].get_feature('train', '<default_output>'),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=2\n",
    "    )\n",
    "    reference_models.append(\n",
    "        TensorflowModel(model_obj=reference_model, loss_fn=loss_fn)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2cf473",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Information Sources\n",
    "\n",
    "We can now define two `InformationSource` objects. Basically, an information source is an abstraction representing a set of models, and their corresponding dataset. Note that for the `ReferenceMetric` we use the same dataset in both the target and reference information sources, but the models that will be used for querying the dataset will differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ffcbae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_info_source = InformationSource(\n",
    "    models=[target_model],\n",
    "    datasets=[datasets_list[0]]\n",
    ")\n",
    "\n",
    "reference_info_source = InformationSource(\n",
    "    models=reference_models,\n",
    "    datasets=[datasets_list[0]] # we use the same dataset for the reference models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83dd40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metric and Audit\n",
    "\n",
    "We now create a `Metric` object, which is an abstraction representing an algorithm used to measure something on an `InformationSource`, such as membership information leakage. In this case, we use the `ReferenceMetric` to measure the membership information leakage of `target_info_source` in a black-box setting, using loss values returned by the reference model on the target dataset in `reference_info_source`.\n",
    "\n",
    "The `Audit` object is a wrapper to actually run the audit, and display the results. More visualization options will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9464f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_itp_threshold_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-705960f206f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mreference_info_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_info_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msignals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModelLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhypothesis_test_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_itp_threshold_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlogs_dirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tutorial_reference_metric'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_itp_threshold_func' is not defined"
     ]
    }
   ],
   "source": [
    "reference_metric = ReferenceMetric(\n",
    "    target_info_source=target_info_source,\n",
    "    reference_info_source=reference_info_source,\n",
    "    signals=[ModelLoss()],\n",
    "    hypothesis_test_func=linear_itp_threshold_func,\n",
    "    logs_dirname='tutorial_reference_metric'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee2a66",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audit_obj = Audit(\n",
    "    metrics=[reference_metric],\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    target_info_sources=[target_info_source],\n",
    "    reference_info_sources=[reference_info_source],\n",
    "    fpr_tolerances=fpr_tolerance_list\n",
    ")\n",
    "audit_obj.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c53b1",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audit_results = audit_obj.run()[0]\n",
    "for result in audit_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec9d4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Result visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d92efb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Several visualization tools are built in `privacy_tool`, such as ROC curves, signal values histogram, or confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a513b2",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This instruction won't be needed once the tool is on pip\n",
    "from privacy_meter import audit_report\n",
    "audit_report.REPORT_FILES_DIR = '../privacy_meter/report_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326f16a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ROCCurveReport.generate_report(\n",
    "    metric_result=audit_results,\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573603e",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SignalHistogramReport.generate_report(\n",
    "    metric_result=result,\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    show=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

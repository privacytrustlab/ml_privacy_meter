


run: # Configurations for a specific run
  random_seed: 12345 # Integer number of specifying random seed
  log_dir: demo_dp_train_natural_1000 # String for indicating where to save all the information, including models and computed signals. We can reuse the models saved in the same log_dir.
  time_log: True # Indicate whether to log the time for each step
  num_experiments: 1 # Number of total experiments

audit: # Configurations for auditing
  privacy_game: privacy_loss_model # Indicate the privacy game from privacy_loss_model
  algorithm: RMIA # String for indicating the membership inference attack. We currently support the RMIA introduced by Zarifzadeh et al. 2024(https://openreview.net/pdf?id=sT7UJh5CTc)) and the LOSS attacks
  num_ref_models: 1 # Number of reference models used to audit each target model
  device: cuda:0 # String for indicating the device we want to use for inferring signals and auditing models
  report_log: report_rmia # String that indicates the folder where we save the log and auditing report
  batch_size: 5000 # Integer number for indicating batch size for evaluating models and inferring signals.
#  data_size: 10000 # Integer number for indicating the size of the dataset in auditing. If not specified, the entire dataset is used.

train: # Configuration for training
  model_name: CNN # String for indicating the model type. We support CNN, wrn28-1, wrn28-2, wrn28-10, vgg16, mlp and speedyresnet (requires cuda). More model types can be added in model.py.
  device: cuda:0 # String for indicating the device we want to use for training models.
  batch_size: 256
  optimizer: SGD
  learning_rate: 20
  weight_decay: 0
  epochs: 200


dp_audit:
  canary_dataset: none # String indicates the name of the canary dataset. We support cifar10_canary or none
  canary_size: 1000
  training_alg: 'dp'


data: # Configuration for data
  dataset: cifar10 # String indicates the name of the dataset. We support cifar10, cifar100, purchase100 and texas100 by default.
  data_dir: data

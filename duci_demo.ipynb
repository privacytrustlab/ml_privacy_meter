{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Usage Cardinality Inference Demo\n",
    "Did your model train on my data? More importantly, does its use qualify as fair use, or does it infringe on my copyright? As AI continues to advance, this question becomes increasingly critical. According to Section 107 of the U.S. Copyright Act, determining whether a use constitutes fair use or copyright infringement requires evaluating the \"_amount and substantiality of the portion used in relation to the copyrighted work_\" under the \"_nature of the copyrighted work_.\" This raises a key question: **how much of a given dataset was used to train a machine learning model?**\n",
    "\n",
    "Dataset Usage Cardinality Inference (DUCI) provides an answer. It enables data owners to assess the risk of unauthorized usage and protect their rights by estimating the exact proportion of data used. DUCI achieves this through a debiasing process that aggregates individual Membership Inference Attack (MIA) guesses to deliver accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Overview\n",
    "The Dataset Usage Cardinality Inference (DUCI) algorithm---acting as an agent for the dataset owner with full access to a target dataset---aims to estimate the proportion of the target dataset used in training a victim model, given black-box access to the model and knowledge of the training algorithm (e.g., the population data and model archtecture).\n",
    "\n",
    "<img src=\"documentation/images/duci_problem.png\" alt=\"Problem Illustration\" title=\"Simple DUCI Pipeline\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy torch  # Install NumPy and PyTorch if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yao/.conda/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-06 10:48:40,503 - INFO - PyTorch version 2.4.0 available.\n",
      "2025-02-06 10:48:41,803 - DEBUG - matplotlib data path: /home/yao/.conda/envs/pytorch/lib/python3.8/site-packages/matplotlib/mpl-data\n",
      "2025-02-06 10:48:41,808 - DEBUG - CONFIGDIR=/home/yao/.config/matplotlib\n",
      "2025-02-06 10:48:41,809 - DEBUG - interactive is False\n",
      "2025-02-06 10:48:41,810 - DEBUG - platform is linux\n",
      "2025-02-06 10:48:42,000 - DEBUG - CACHEDIR=/home/yao/.cache/matplotlib\n",
      "2025-02-06 10:48:42,003 - DEBUG - Using fontManager instance from /home/yao/.cache/matplotlib/fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "from dataset import get_dataset\n",
    "from models.utils import train_models, load_models\n",
    "from get_signals import get_model_signals\n",
    "from audit import sample_auditing_dataset\n",
    "from modules.duci import DUCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "As the dataset owner, we have a target dataset $X$ and access to a population pool. For simplicity, assume the population pool is the CIFAR-10 dataset, and we sample a subset $X$ of size 500 from this pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Configs\n",
    "_dataset = 'cifar10' # cifar10 as the population pool\n",
    "dataset_dir = 'data'\n",
    "log_dir = 'demo_duci'\n",
    "configs = {\n",
    "    'run': {\n",
    "        'random_seed': 12345,\n",
    "        'log_dir': 'demo_duci',\n",
    "        'time_log': True,\n",
    "        'num_experiments': 1\n",
    "    },\n",
    "    'audit': {\n",
    "        'privacy_game': 'privacy_loss_model',\n",
    "        'algorithm': 'RMIA',\n",
    "        'num_ref_models': 1,\n",
    "        'device': 'cuda:0',\n",
    "        'report_log': 'report_rmia',\n",
    "        'batch_size': 5000\n",
    "    },\n",
    "    'train': {\n",
    "        'model_name': 'wrn28-2',\n",
    "        'device': 'cuda:0',\n",
    "        'batch_size': 256,\n",
    "        'optimizer': 'SGD',\n",
    "        'learning_rate': 0.1,\n",
    "        'weight_decay': 0,\n",
    "        'epochs': 100\n",
    "    },\n",
    "    'data': {\n",
    "        'dataset': 'cifar10',\n",
    "        'data_dir': 'data'\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 10:48:42,243 - INFO - Data loaded from data/cifar10.pkl\n",
      "2025-02-06 10:48:42,257 - INFO - Population data loaded from data/cifar10_population.pkl\n",
      "2025-02-06 10:48:42,258 - INFO - The whole dataset size: 50000\n"
     ]
    }
   ],
   "source": [
    "dataset, population = get_dataset(_dataset, dataset_dir, logger)\n",
    "\n",
    "# Select 500 points from the dataset as the target dataset\n",
    "all_indices = list(range(len(dataset)))\n",
    "random.shuffle(all_indices)\n",
    "target_indices = all_indices[:500]\n",
    "remaining_indices = all_indices[500:]\n",
    "TRAIN_SIZE = len(dataset) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the victim model\n",
    "Suppose a victim model is trained on a randomly selected $p$ proportion of our dataset $X$. Our goal is to infer the value of $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "p = random.choice(proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selection 0.3 proportion of the target dataset\n",
    "selected_indices = random.sample(target_indices, int(p * len(target_indices)))\n",
    "remaining_size = TRAIN_SIZE - len(selected_indices)\n",
    "selected_remaining_indices = random.sample(remaining_indices, remaining_size)\n",
    "selected_victim_indices = selected_indices + selected_remaining_indices\n",
    "\n",
    "# select all unselected indices in all_indices as the test indices\n",
    "test_indices = list(set(all_indices) - set(selected_indices) - set(selected_remaining_indices))\n",
    "target_data_split = {\n",
    "    'train': selected_victim_indices,\n",
    "    'test': test_indices\n",
    "}\n",
    "target_membership = np.zeros(len(dataset))\n",
    "target_membership[selected_victim_indices] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train reference models\n",
    "\n",
    "In the **Privacy Meter** library, $2N$ reference models are trained by default, ensuring that each data point is included in one model's training set and excluded from another. We first explore dataset usage inference using two reference models before moving to the special case of single-reference models (by adapting the MIA implementations in the library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selection half of the target dataset\n",
    "ref_selected_indices = random.sample(target_indices, int(0.5 * len(target_indices)))\n",
    "ref_remaining_size = TRAIN_SIZE - len(ref_selected_indices)\n",
    "ref_selected_remaining_indices = random.sample(remaining_indices, ref_remaining_size)\n",
    "ref_selected_victim_indices = ref_selected_indices + ref_selected_remaining_indices\n",
    "\n",
    "# select all unselected indices in all_indices as the test indices\n",
    "ref_test_indices = list(set(all_indices) - set(ref_selected_indices) - set(ref_selected_remaining_indices))\n",
    "ref_data_split = {\n",
    "    'train': ref_selected_victim_indices,\n",
    "    'test': ref_test_indices\n",
    "}\n",
    "ref_membership = np.zeros(len(dataset))\n",
    "ref_membership[ref_selected_victim_indices] = 1\n",
    "\n",
    "# Get the pair reference model\n",
    "ref_paired_selected_indices = list(set(target_indices)-set(ref_selected_indices))\n",
    "ref_paired_remaining_size = TRAIN_SIZE - len(ref_paired_selected_indices)\n",
    "ref_paired_selected_remaining_indices = random.sample(remaining_indices, ref_paired_remaining_size)\n",
    "ref_paired_selected_victim_indices = ref_paired_selected_indices + ref_paired_selected_remaining_indices\n",
    "\n",
    "# select all unselected indices in all_indices as the test indices\n",
    "ref_paired_test_indices = list(set(all_indices) - set(ref_paired_selected_indices) - set(ref_paired_selected_remaining_indices))\n",
    "ref_paired_data_split = {\n",
    "    'train': ref_paired_selected_victim_indices,\n",
    "    'test': ref_paired_test_indices\n",
    "}\n",
    "ref_paired_membership = np.zeros(len(dataset))\n",
    "ref_paired_membership[ref_paired_selected_victim_indices] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 10:48:42,377 - INFO - Training 3 models\n",
      "2025-02-06 10:48:42,378 - INFO - --------------------------------------------------\n",
      "2025-02-06 10:48:42,379 - INFO - Training model 0: Train size 25000, Test size 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 2.2799 | Train Acc: 0.1453\n",
      "Test Loss: 2.1548 | Test Acc: 0.2206\n",
      "Epoch 1 took 5.23 seconds\n",
      "Epoch [2/100] | Train Loss: 1.9888 | Train Acc: 0.2802\n",
      "Test Loss: 1.8909 | Test Acc: 0.3122\n",
      "Epoch 2 took 4.48 seconds\n",
      "Epoch [3/100] | Train Loss: 1.8115 | Train Acc: 0.3394\n",
      "Test Loss: 1.7629 | Test Acc: 0.3470\n",
      "Epoch 3 took 4.48 seconds\n",
      "Epoch [4/100] | Train Loss: 1.7004 | Train Acc: 0.3787\n",
      "Test Loss: 1.6773 | Test Acc: 0.3786\n",
      "Epoch 4 took 4.47 seconds\n",
      "Epoch [5/100] | Train Loss: 1.5988 | Train Acc: 0.4187\n",
      "Test Loss: 1.6252 | Test Acc: 0.4007\n",
      "Epoch 5 took 4.51 seconds\n",
      "Epoch [6/100] | Train Loss: 1.4959 | Train Acc: 0.4536\n",
      "Test Loss: 1.6081 | Test Acc: 0.4052\n",
      "Epoch 6 took 4.56 seconds\n",
      "Epoch [7/100] | Train Loss: 1.4038 | Train Acc: 0.4946\n",
      "Test Loss: 1.6123 | Test Acc: 0.4241\n",
      "Epoch 7 took 4.49 seconds\n",
      "Epoch [8/100] | Train Loss: 1.3240 | Train Acc: 0.5260\n",
      "Test Loss: 1.3616 | Test Acc: 0.5117\n",
      "Epoch 8 took 4.50 seconds\n",
      "Epoch [9/100] | Train Loss: 1.2541 | Train Acc: 0.5495\n",
      "Test Loss: 1.3515 | Test Acc: 0.5019\n",
      "Epoch 9 took 4.50 seconds\n",
      "Epoch [10/100] | Train Loss: 1.1943 | Train Acc: 0.5732\n",
      "Test Loss: 1.3033 | Test Acc: 0.5277\n",
      "Epoch 10 took 4.54 seconds\n",
      "Epoch [11/100] | Train Loss: 1.1285 | Train Acc: 0.5950\n",
      "Test Loss: 1.7833 | Test Acc: 0.4346\n",
      "Epoch 11 took 4.52 seconds\n",
      "Epoch [12/100] | Train Loss: 1.0801 | Train Acc: 0.6148\n",
      "Test Loss: 1.5102 | Test Acc: 0.4731\n",
      "Epoch 12 took 4.54 seconds\n",
      "Epoch [13/100] | Train Loss: 1.0266 | Train Acc: 0.6367\n",
      "Test Loss: 1.9902 | Test Acc: 0.4082\n",
      "Epoch 13 took 4.50 seconds\n",
      "Epoch [14/100] | Train Loss: 0.9813 | Train Acc: 0.6510\n",
      "Test Loss: 1.3506 | Test Acc: 0.5386\n",
      "Epoch 14 took 4.51 seconds\n",
      "Epoch [15/100] | Train Loss: 0.9324 | Train Acc: 0.6716\n",
      "Test Loss: 2.6678 | Test Acc: 0.3557\n",
      "Epoch 15 took 4.53 seconds\n",
      "Epoch [16/100] | Train Loss: 0.8876 | Train Acc: 0.6895\n",
      "Test Loss: 1.3134 | Test Acc: 0.5481\n",
      "Epoch 16 took 4.52 seconds\n",
      "Epoch [17/100] | Train Loss: 0.8520 | Train Acc: 0.7006\n",
      "Test Loss: 1.5249 | Test Acc: 0.4902\n",
      "Epoch 17 took 4.55 seconds\n",
      "Epoch [18/100] | Train Loss: 0.8033 | Train Acc: 0.7191\n",
      "Test Loss: 1.3969 | Test Acc: 0.5257\n",
      "Epoch 18 took 4.51 seconds\n",
      "Epoch [19/100] | Train Loss: 0.7675 | Train Acc: 0.7357\n",
      "Test Loss: 1.6197 | Test Acc: 0.4929\n",
      "Epoch 19 took 4.56 seconds\n",
      "Epoch [20/100] | Train Loss: 0.7195 | Train Acc: 0.7517\n",
      "Test Loss: 1.2572 | Test Acc: 0.5827\n",
      "Epoch 20 took 4.56 seconds\n",
      "Epoch [21/100] | Train Loss: 0.6710 | Train Acc: 0.7698\n",
      "Test Loss: 1.2056 | Test Acc: 0.5914\n",
      "Epoch 21 took 4.55 seconds\n",
      "Epoch [22/100] | Train Loss: 0.6336 | Train Acc: 0.7834\n",
      "Test Loss: 1.4309 | Test Acc: 0.5704\n",
      "Epoch 22 took 4.56 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5867 | Train Acc: 0.8034\n",
      "Test Loss: 1.9457 | Test Acc: 0.4667\n",
      "Epoch 23 took 4.53 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5532 | Train Acc: 0.8156\n",
      "Test Loss: 1.6389 | Test Acc: 0.5137\n",
      "Epoch 24 took 4.53 seconds\n",
      "Epoch [25/100] | Train Loss: 0.5033 | Train Acc: 0.8330\n",
      "Test Loss: 3.9528 | Test Acc: 0.3306\n",
      "Epoch 25 took 4.52 seconds\n",
      "Epoch [26/100] | Train Loss: 0.4523 | Train Acc: 0.8535\n",
      "Test Loss: 1.9833 | Test Acc: 0.4524\n",
      "Epoch 26 took 4.55 seconds\n",
      "Epoch [27/100] | Train Loss: 0.4137 | Train Acc: 0.8668\n",
      "Test Loss: 2.3957 | Test Acc: 0.4275\n",
      "Epoch 27 took 4.52 seconds\n",
      "Epoch [28/100] | Train Loss: 0.3747 | Train Acc: 0.8815\n",
      "Test Loss: 1.8527 | Test Acc: 0.4966\n",
      "Epoch 28 took 4.52 seconds\n",
      "Epoch [29/100] | Train Loss: 0.3280 | Train Acc: 0.9027\n",
      "Test Loss: 2.5374 | Test Acc: 0.4651\n",
      "Epoch 29 took 4.52 seconds\n",
      "Epoch [30/100] | Train Loss: 0.3039 | Train Acc: 0.9095\n",
      "Test Loss: 2.3012 | Test Acc: 0.4413\n",
      "Epoch 30 took 4.54 seconds\n",
      "Epoch [31/100] | Train Loss: 0.2504 | Train Acc: 0.9319\n",
      "Test Loss: 1.9932 | Test Acc: 0.5040\n",
      "Epoch 31 took 4.56 seconds\n",
      "Epoch [32/100] | Train Loss: 0.2023 | Train Acc: 0.9483\n",
      "Test Loss: 2.1256 | Test Acc: 0.5000\n",
      "Epoch 32 took 4.53 seconds\n",
      "Epoch [33/100] | Train Loss: 0.2061 | Train Acc: 0.9455\n",
      "Test Loss: 3.1300 | Test Acc: 0.4204\n",
      "Epoch 33 took 4.51 seconds\n",
      "Epoch [34/100] | Train Loss: 0.1361 | Train Acc: 0.9719\n",
      "Test Loss: 1.8700 | Test Acc: 0.5480\n",
      "Epoch 34 took 4.52 seconds\n",
      "Epoch [35/100] | Train Loss: 0.1096 | Train Acc: 0.9797\n",
      "Test Loss: 1.4354 | Test Acc: 0.5986\n",
      "Epoch 35 took 4.54 seconds\n",
      "Epoch [36/100] | Train Loss: 0.0938 | Train Acc: 0.9835\n",
      "Test Loss: 1.4907 | Test Acc: 0.5873\n",
      "Epoch 36 took 4.52 seconds\n",
      "Epoch [37/100] | Train Loss: 0.0618 | Train Acc: 0.9933\n",
      "Test Loss: 1.6499 | Test Acc: 0.5624\n",
      "Epoch 37 took 4.51 seconds\n",
      "Epoch [38/100] | Train Loss: 0.0426 | Train Acc: 0.9972\n",
      "Test Loss: 1.3125 | Test Acc: 0.6308\n",
      "Epoch 38 took 4.54 seconds\n",
      "Epoch [39/100] | Train Loss: 0.0352 | Train Acc: 0.9978\n",
      "Test Loss: 1.4442 | Test Acc: 0.6146\n",
      "Epoch 39 took 4.55 seconds\n",
      "Epoch [40/100] | Train Loss: 0.0310 | Train Acc: 0.9984\n",
      "Test Loss: 1.3496 | Test Acc: 0.6274\n",
      "Epoch 40 took 4.55 seconds\n",
      "Epoch [41/100] | Train Loss: 0.0256 | Train Acc: 0.9991\n",
      "Test Loss: 1.2869 | Test Acc: 0.6356\n",
      "Epoch 41 took 4.55 seconds\n",
      "Epoch [42/100] | Train Loss: 0.0212 | Train Acc: 0.9996\n",
      "Test Loss: 1.3229 | Test Acc: 0.6299\n",
      "Epoch 42 took 4.53 seconds\n",
      "Epoch [43/100] | Train Loss: 0.0180 | Train Acc: 0.9998\n",
      "Test Loss: 1.3181 | Test Acc: 0.6340\n",
      "Epoch 43 took 4.54 seconds\n",
      "Epoch [44/100] | Train Loss: 0.0171 | Train Acc: 0.9997\n",
      "Test Loss: 1.4609 | Test Acc: 0.6127\n",
      "Epoch 44 took 4.56 seconds\n",
      "Epoch [45/100] | Train Loss: 0.0152 | Train Acc: 0.9999\n",
      "Test Loss: 1.3859 | Test Acc: 0.6293\n",
      "Epoch 45 took 4.54 seconds\n",
      "Epoch [46/100] | Train Loss: 0.0149 | Train Acc: 0.9996\n",
      "Test Loss: 1.4172 | Test Acc: 0.6218\n",
      "Epoch 46 took 4.55 seconds\n",
      "Epoch [47/100] | Train Loss: 0.0123 | Train Acc: 1.0000\n",
      "Test Loss: 1.3596 | Test Acc: 0.6285\n",
      "Epoch 47 took 4.53 seconds\n",
      "Epoch [48/100] | Train Loss: 0.0114 | Train Acc: 1.0000\n",
      "Test Loss: 1.3693 | Test Acc: 0.6331\n",
      "Epoch 48 took 4.53 seconds\n",
      "Epoch [49/100] | Train Loss: 0.0111 | Train Acc: 0.9998\n",
      "Test Loss: 1.3929 | Test Acc: 0.6251\n",
      "Epoch 49 took 4.55 seconds\n",
      "Epoch [50/100] | Train Loss: 0.0104 | Train Acc: 0.9999\n",
      "Test Loss: 1.3853 | Test Acc: 0.6321\n",
      "Epoch 50 took 4.53 seconds\n",
      "Epoch [51/100] | Train Loss: 0.0095 | Train Acc: 1.0000\n",
      "Test Loss: 1.3656 | Test Acc: 0.6308\n",
      "Epoch 51 took 4.56 seconds\n",
      "Epoch [52/100] | Train Loss: 0.0090 | Train Acc: 1.0000\n",
      "Test Loss: 1.4437 | Test Acc: 0.6210\n",
      "Epoch 52 took 4.56 seconds\n",
      "Epoch [53/100] | Train Loss: 0.0087 | Train Acc: 1.0000\n",
      "Test Loss: 1.3854 | Test Acc: 0.6311\n",
      "Epoch 53 took 4.54 seconds\n",
      "Epoch [54/100] | Train Loss: 0.0084 | Train Acc: 1.0000\n",
      "Test Loss: 1.4208 | Test Acc: 0.6263\n",
      "Epoch 54 took 4.56 seconds\n",
      "Epoch [55/100] | Train Loss: 0.0079 | Train Acc: 1.0000\n",
      "Test Loss: 1.3673 | Test Acc: 0.6355\n",
      "Epoch 55 took 4.55 seconds\n",
      "Epoch [56/100] | Train Loss: 0.0080 | Train Acc: 1.0000\n",
      "Test Loss: 1.4129 | Test Acc: 0.6269\n",
      "Epoch 56 took 4.55 seconds\n",
      "Epoch [57/100] | Train Loss: 0.0073 | Train Acc: 1.0000\n",
      "Test Loss: 1.4119 | Test Acc: 0.6298\n",
      "Epoch 57 took 4.53 seconds\n",
      "Epoch [58/100] | Train Loss: 0.0069 | Train Acc: 1.0000\n",
      "Test Loss: 1.3888 | Test Acc: 0.6259\n",
      "Epoch 58 took 4.54 seconds\n",
      "Epoch [59/100] | Train Loss: 0.0068 | Train Acc: 1.0000\n",
      "Test Loss: 1.4187 | Test Acc: 0.6311\n",
      "Epoch 59 took 4.57 seconds\n",
      "Epoch [60/100] | Train Loss: 0.0068 | Train Acc: 1.0000\n",
      "Test Loss: 1.4522 | Test Acc: 0.6296\n",
      "Epoch 60 took 4.56 seconds\n",
      "Epoch [61/100] | Train Loss: 0.0067 | Train Acc: 1.0000\n",
      "Test Loss: 1.4360 | Test Acc: 0.6260\n",
      "Epoch 61 took 4.54 seconds\n",
      "Epoch [62/100] | Train Loss: 0.0064 | Train Acc: 1.0000\n",
      "Test Loss: 1.4287 | Test Acc: 0.6270\n",
      "Epoch 62 took 4.54 seconds\n",
      "Epoch [63/100] | Train Loss: 0.0062 | Train Acc: 1.0000\n",
      "Test Loss: 1.4182 | Test Acc: 0.6302\n",
      "Epoch 63 took 4.56 seconds\n",
      "Epoch [64/100] | Train Loss: 0.0057 | Train Acc: 1.0000\n",
      "Test Loss: 1.4243 | Test Acc: 0.6345\n",
      "Epoch 64 took 4.57 seconds\n",
      "Epoch [65/100] | Train Loss: 0.0056 | Train Acc: 1.0000\n",
      "Test Loss: 1.4549 | Test Acc: 0.6277\n",
      "Epoch 65 took 4.52 seconds\n",
      "Epoch [66/100] | Train Loss: 0.0055 | Train Acc: 1.0000\n",
      "Test Loss: 1.4502 | Test Acc: 0.6290\n",
      "Epoch 66 took 4.56 seconds\n",
      "Epoch [67/100] | Train Loss: 0.0055 | Train Acc: 1.0000\n",
      "Test Loss: 1.4704 | Test Acc: 0.6280\n",
      "Epoch 67 took 4.52 seconds\n",
      "Epoch [68/100] | Train Loss: 0.0050 | Train Acc: 1.0000\n",
      "Test Loss: 1.4665 | Test Acc: 0.6285\n",
      "Epoch 68 took 4.58 seconds\n",
      "Epoch [69/100] | Train Loss: 0.0054 | Train Acc: 1.0000\n",
      "Test Loss: 1.4242 | Test Acc: 0.6322\n",
      "Epoch 69 took 4.55 seconds\n",
      "Epoch [70/100] | Train Loss: 0.0053 | Train Acc: 1.0000\n",
      "Test Loss: 1.4307 | Test Acc: 0.6276\n",
      "Epoch 70 took 4.53 seconds\n",
      "Epoch [71/100] | Train Loss: 0.0050 | Train Acc: 1.0000\n",
      "Test Loss: 1.4620 | Test Acc: 0.6254\n",
      "Epoch 71 took 4.54 seconds\n",
      "Epoch [72/100] | Train Loss: 0.0050 | Train Acc: 1.0000\n",
      "Test Loss: 1.4827 | Test Acc: 0.6263\n",
      "Epoch 72 took 4.56 seconds\n",
      "Epoch [73/100] | Train Loss: 0.0052 | Train Acc: 1.0000\n",
      "Test Loss: 1.4700 | Test Acc: 0.6229\n",
      "Epoch 73 took 4.54 seconds\n",
      "Epoch [74/100] | Train Loss: 0.0048 | Train Acc: 1.0000\n",
      "Test Loss: 1.4677 | Test Acc: 0.6305\n",
      "Epoch 74 took 4.53 seconds\n",
      "Epoch [75/100] | Train Loss: 0.0047 | Train Acc: 1.0000\n",
      "Test Loss: 1.4365 | Test Acc: 0.6302\n",
      "Epoch 75 took 4.55 seconds\n",
      "Epoch [76/100] | Train Loss: 0.0046 | Train Acc: 1.0000\n",
      "Test Loss: 1.4341 | Test Acc: 0.6278\n",
      "Epoch 76 took 4.55 seconds\n",
      "Epoch [77/100] | Train Loss: 0.0045 | Train Acc: 1.0000\n",
      "Test Loss: 1.4909 | Test Acc: 0.6275\n",
      "Epoch 77 took 4.53 seconds\n",
      "Epoch [78/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.4144 | Test Acc: 0.6308\n",
      "Epoch 78 took 4.54 seconds\n",
      "Epoch [79/100] | Train Loss: 0.0045 | Train Acc: 1.0000\n",
      "Test Loss: 1.4636 | Test Acc: 0.6285\n",
      "Epoch 79 took 4.51 seconds\n",
      "Epoch [80/100] | Train Loss: 0.0044 | Train Acc: 1.0000\n",
      "Test Loss: 1.4661 | Test Acc: 0.6270\n",
      "Epoch 80 took 4.55 seconds\n",
      "Epoch [81/100] | Train Loss: 0.0046 | Train Acc: 1.0000\n",
      "Test Loss: 1.4528 | Test Acc: 0.6260\n",
      "Epoch 81 took 4.53 seconds\n",
      "Epoch [82/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.4753 | Test Acc: 0.6260\n",
      "Epoch 82 took 4.52 seconds\n",
      "Epoch [83/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.5504 | Test Acc: 0.6183\n",
      "Epoch 83 took 4.55 seconds\n",
      "Epoch [84/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.5705 | Test Acc: 0.6195\n",
      "Epoch 84 took 4.56 seconds\n",
      "Epoch [85/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4893 | Test Acc: 0.6290\n",
      "Epoch 85 took 4.53 seconds\n",
      "Epoch [86/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.4475 | Test Acc: 0.6339\n",
      "Epoch 86 took 4.52 seconds\n",
      "Epoch [87/100] | Train Loss: 0.0043 | Train Acc: 1.0000\n",
      "Test Loss: 1.4429 | Test Acc: 0.6308\n",
      "Epoch 87 took 4.56 seconds\n",
      "Epoch [88/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4575 | Test Acc: 0.6310\n",
      "Epoch 88 took 4.52 seconds\n",
      "Epoch [89/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4603 | Test Acc: 0.6281\n",
      "Epoch 89 took 4.56 seconds\n",
      "Epoch [90/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4508 | Test Acc: 0.6297\n",
      "Epoch 90 took 4.53 seconds\n",
      "Epoch [91/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4577 | Test Acc: 0.6274\n",
      "Epoch 91 took 4.54 seconds\n",
      "Epoch [92/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.5767 | Test Acc: 0.6221\n",
      "Epoch 92 took 4.52 seconds\n",
      "Epoch [93/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4839 | Test Acc: 0.6310\n",
      "Epoch 93 took 4.59 seconds\n",
      "Epoch [94/100] | Train Loss: 0.0036 | Train Acc: 1.0000\n",
      "Test Loss: 1.5413 | Test Acc: 0.6175\n",
      "Epoch 94 took 4.56 seconds\n",
      "Epoch [95/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.4703 | Test Acc: 0.6296\n",
      "Epoch 95 took 4.52 seconds\n",
      "Epoch [96/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.5414 | Test Acc: 0.6265\n",
      "Epoch 96 took 4.55 seconds\n",
      "Epoch [97/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4742 | Test Acc: 0.6288\n",
      "Epoch 97 took 4.52 seconds\n",
      "Epoch [98/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4984 | Test Acc: 0.6273\n",
      "Epoch 98 took 4.54 seconds\n",
      "Epoch [99/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4590 | Test Acc: 0.6297\n",
      "Epoch 99 took 4.55 seconds\n",
      "Epoch [100/100] | Train Loss: 0.0036 | Train Acc: 1.0000\n",
      "Test Loss: 1.4591 | Test Acc: 0.6286\n",
      "Epoch 100 took 4.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 10:56:19,160 - INFO - Train accuracy 1.0, Train Loss 0.0030490692529105104\n",
      "2025-02-06 10:56:19,161 - INFO - Test accuracy 0.62864, Test Loss 1.4608709082311513\n",
      "2025-02-06 10:56:19,176 - INFO - Training model 0 took 456.7981164455414 seconds\n",
      "2025-02-06 10:56:19,194 - INFO - --------------------------------------------------\n",
      "2025-02-06 10:56:19,195 - INFO - Training model 1: Train size 25000, Test size 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 2.2567 | Train Acc: 0.1633\n",
      "Test Loss: 2.1042 | Test Acc: 0.2538\n",
      "Epoch 1 took 4.77 seconds\n",
      "Epoch [2/100] | Train Loss: 1.9471 | Train Acc: 0.2964\n",
      "Test Loss: 1.8366 | Test Acc: 0.3292\n",
      "Epoch 2 took 4.53 seconds\n",
      "Epoch [3/100] | Train Loss: 1.7635 | Train Acc: 0.3561\n",
      "Test Loss: 1.7545 | Test Acc: 0.3572\n",
      "Epoch 3 took 4.51 seconds\n",
      "Epoch [4/100] | Train Loss: 1.6477 | Train Acc: 0.3928\n",
      "Test Loss: 1.6086 | Test Acc: 0.4052\n",
      "Epoch 4 took 4.53 seconds\n",
      "Epoch [5/100] | Train Loss: 1.5520 | Train Acc: 0.4299\n",
      "Test Loss: 1.6251 | Test Acc: 0.3972\n",
      "Epoch 5 took 4.54 seconds\n",
      "Epoch [6/100] | Train Loss: 1.4620 | Train Acc: 0.4654\n",
      "Test Loss: 1.4798 | Test Acc: 0.4474\n",
      "Epoch 6 took 4.52 seconds\n",
      "Epoch [7/100] | Train Loss: 1.3772 | Train Acc: 0.4981\n",
      "Test Loss: 1.4301 | Test Acc: 0.4773\n",
      "Epoch 7 took 4.56 seconds\n",
      "Epoch [8/100] | Train Loss: 1.3029 | Train Acc: 0.5299\n",
      "Test Loss: 1.3670 | Test Acc: 0.5102\n",
      "Epoch 8 took 4.55 seconds\n",
      "Epoch [9/100] | Train Loss: 1.2387 | Train Acc: 0.5534\n",
      "Test Loss: 1.6398 | Test Acc: 0.4462\n",
      "Epoch 9 took 4.55 seconds\n",
      "Epoch [10/100] | Train Loss: 1.1798 | Train Acc: 0.5752\n",
      "Test Loss: 1.2910 | Test Acc: 0.5328\n",
      "Epoch 10 took 4.52 seconds\n",
      "Epoch [11/100] | Train Loss: 1.1224 | Train Acc: 0.6024\n",
      "Test Loss: 1.2550 | Test Acc: 0.5395\n",
      "Epoch 11 took 4.57 seconds\n",
      "Epoch [12/100] | Train Loss: 1.0691 | Train Acc: 0.6201\n",
      "Test Loss: 1.3031 | Test Acc: 0.5110\n",
      "Epoch 12 took 4.53 seconds\n",
      "Epoch [13/100] | Train Loss: 1.0179 | Train Acc: 0.6362\n",
      "Test Loss: 1.1522 | Test Acc: 0.5820\n",
      "Epoch 13 took 4.54 seconds\n",
      "Epoch [14/100] | Train Loss: 0.9580 | Train Acc: 0.6622\n",
      "Test Loss: 1.2280 | Test Acc: 0.5493\n",
      "Epoch 14 took 4.54 seconds\n",
      "Epoch [15/100] | Train Loss: 0.9180 | Train Acc: 0.6727\n",
      "Test Loss: 1.3259 | Test Acc: 0.5291\n",
      "Epoch 15 took 4.53 seconds\n",
      "Epoch [16/100] | Train Loss: 0.8756 | Train Acc: 0.6928\n",
      "Test Loss: 1.8539 | Test Acc: 0.4392\n",
      "Epoch 16 took 4.52 seconds\n",
      "Epoch [17/100] | Train Loss: 0.8244 | Train Acc: 0.7122\n",
      "Test Loss: 1.3176 | Test Acc: 0.5407\n",
      "Epoch 17 took 4.51 seconds\n",
      "Epoch [18/100] | Train Loss: 0.7825 | Train Acc: 0.7286\n",
      "Test Loss: 1.3099 | Test Acc: 0.5455\n",
      "Epoch 18 took 4.58 seconds\n",
      "Epoch [19/100] | Train Loss: 0.7409 | Train Acc: 0.7425\n",
      "Test Loss: 1.6022 | Test Acc: 0.5064\n",
      "Epoch 19 took 4.53 seconds\n",
      "Epoch [20/100] | Train Loss: 0.6966 | Train Acc: 0.7578\n",
      "Test Loss: 1.3397 | Test Acc: 0.5610\n",
      "Epoch 20 took 4.52 seconds\n",
      "Epoch [21/100] | Train Loss: 0.6467 | Train Acc: 0.7810\n",
      "Test Loss: 1.8381 | Test Acc: 0.4851\n",
      "Epoch 21 took 4.52 seconds\n",
      "Epoch [22/100] | Train Loss: 0.6081 | Train Acc: 0.7943\n",
      "Test Loss: 1.3845 | Test Acc: 0.5676\n",
      "Epoch 22 took 4.54 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5590 | Train Acc: 0.8140\n",
      "Test Loss: 2.1019 | Test Acc: 0.4944\n",
      "Epoch 23 took 4.53 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5134 | Train Acc: 0.8304\n",
      "Test Loss: 1.5996 | Test Acc: 0.5247\n",
      "Epoch 24 took 4.55 seconds\n",
      "Epoch [25/100] | Train Loss: 0.4778 | Train Acc: 0.8450\n",
      "Test Loss: 1.5348 | Test Acc: 0.5348\n",
      "Epoch 25 took 4.55 seconds\n",
      "Epoch [26/100] | Train Loss: 0.4265 | Train Acc: 0.8646\n",
      "Test Loss: 2.0223 | Test Acc: 0.4566\n",
      "Epoch 26 took 4.54 seconds\n",
      "Epoch [27/100] | Train Loss: 0.3756 | Train Acc: 0.8845\n",
      "Test Loss: 1.5140 | Test Acc: 0.5560\n",
      "Epoch 27 took 4.52 seconds\n",
      "Epoch [28/100] | Train Loss: 0.3224 | Train Acc: 0.9025\n",
      "Test Loss: 2.0606 | Test Acc: 0.4884\n",
      "Epoch 28 took 4.53 seconds\n",
      "Epoch [29/100] | Train Loss: 0.2882 | Train Acc: 0.9155\n",
      "Test Loss: 1.7579 | Test Acc: 0.5391\n",
      "Epoch 29 took 4.53 seconds\n",
      "Epoch [30/100] | Train Loss: 0.2534 | Train Acc: 0.9293\n",
      "Test Loss: 3.5788 | Test Acc: 0.3734\n",
      "Epoch 30 took 4.57 seconds\n",
      "Epoch [31/100] | Train Loss: 0.1937 | Train Acc: 0.9535\n",
      "Test Loss: 1.5720 | Test Acc: 0.5894\n",
      "Epoch 31 took 4.50 seconds\n",
      "Epoch [32/100] | Train Loss: 0.1465 | Train Acc: 0.9699\n",
      "Test Loss: 1.8840 | Test Acc: 0.5224\n",
      "Epoch 32 took 4.53 seconds\n",
      "Epoch [33/100] | Train Loss: 0.1165 | Train Acc: 0.9785\n",
      "Test Loss: 1.8442 | Test Acc: 0.5591\n",
      "Epoch 33 took 4.53 seconds\n",
      "Epoch [34/100] | Train Loss: 0.1016 | Train Acc: 0.9822\n",
      "Test Loss: 1.8047 | Test Acc: 0.5540\n",
      "Epoch 34 took 4.57 seconds\n",
      "Epoch [35/100] | Train Loss: 0.0630 | Train Acc: 0.9938\n",
      "Test Loss: 1.2411 | Test Acc: 0.6426\n",
      "Epoch 35 took 4.57 seconds\n",
      "Epoch [36/100] | Train Loss: 0.0463 | Train Acc: 0.9962\n",
      "Test Loss: 1.3119 | Test Acc: 0.6231\n",
      "Epoch 36 took 4.57 seconds\n",
      "Epoch [37/100] | Train Loss: 0.0365 | Train Acc: 0.9980\n",
      "Test Loss: 1.3289 | Test Acc: 0.6318\n",
      "Epoch 37 took 4.53 seconds\n",
      "Epoch [38/100] | Train Loss: 0.0308 | Train Acc: 0.9986\n",
      "Test Loss: 1.2309 | Test Acc: 0.6467\n",
      "Epoch 38 took 4.51 seconds\n",
      "Epoch [39/100] | Train Loss: 0.0242 | Train Acc: 0.9992\n",
      "Test Loss: 1.3626 | Test Acc: 0.6300\n",
      "Epoch 39 took 4.54 seconds\n",
      "Epoch [40/100] | Train Loss: 0.0219 | Train Acc: 0.9993\n",
      "Test Loss: 1.2823 | Test Acc: 0.6480\n",
      "Epoch 40 took 4.53 seconds\n",
      "Epoch [41/100] | Train Loss: 0.0182 | Train Acc: 0.9996\n",
      "Test Loss: 1.2807 | Test Acc: 0.6438\n",
      "Epoch 41 took 4.52 seconds\n",
      "Epoch [42/100] | Train Loss: 0.0167 | Train Acc: 0.9998\n",
      "Test Loss: 1.3179 | Test Acc: 0.6420\n",
      "Epoch 42 took 4.54 seconds\n",
      "Epoch [43/100] | Train Loss: 0.0150 | Train Acc: 0.9998\n",
      "Test Loss: 1.2742 | Test Acc: 0.6417\n",
      "Epoch 43 took 4.51 seconds\n",
      "Epoch [44/100] | Train Loss: 0.0156 | Train Acc: 0.9995\n",
      "Test Loss: 1.2865 | Test Acc: 0.6460\n",
      "Epoch 44 took 4.51 seconds\n",
      "Epoch [45/100] | Train Loss: 0.0129 | Train Acc: 0.9999\n",
      "Test Loss: 1.2870 | Test Acc: 0.6452\n",
      "Epoch 45 took 4.52 seconds\n",
      "Epoch [46/100] | Train Loss: 0.0133 | Train Acc: 0.9996\n",
      "Test Loss: 1.3353 | Test Acc: 0.6372\n",
      "Epoch 46 took 4.51 seconds\n",
      "Epoch [47/100] | Train Loss: 0.0108 | Train Acc: 0.9999\n",
      "Test Loss: 1.2895 | Test Acc: 0.6428\n",
      "Epoch 47 took 4.55 seconds\n",
      "Epoch [48/100] | Train Loss: 0.0101 | Train Acc: 0.9999\n",
      "Test Loss: 1.3296 | Test Acc: 0.6454\n",
      "Epoch 48 took 4.52 seconds\n",
      "Epoch [49/100] | Train Loss: 0.0095 | Train Acc: 1.0000\n",
      "Test Loss: 1.2786 | Test Acc: 0.6483\n",
      "Epoch 49 took 4.57 seconds\n",
      "Epoch [50/100] | Train Loss: 0.0092 | Train Acc: 1.0000\n",
      "Test Loss: 1.3976 | Test Acc: 0.6378\n",
      "Epoch 50 took 4.53 seconds\n",
      "Epoch [51/100] | Train Loss: 0.0085 | Train Acc: 1.0000\n",
      "Test Loss: 1.3675 | Test Acc: 0.6392\n",
      "Epoch 51 took 4.52 seconds\n",
      "Epoch [52/100] | Train Loss: 0.0088 | Train Acc: 0.9999\n",
      "Test Loss: 1.4066 | Test Acc: 0.6362\n",
      "Epoch 52 took 4.54 seconds\n",
      "Epoch [53/100] | Train Loss: 0.0079 | Train Acc: 1.0000\n",
      "Test Loss: 1.3470 | Test Acc: 0.6450\n",
      "Epoch 53 took 4.51 seconds\n",
      "Epoch [54/100] | Train Loss: 0.0076 | Train Acc: 1.0000\n",
      "Test Loss: 1.3518 | Test Acc: 0.6448\n",
      "Epoch 54 took 4.56 seconds\n",
      "Epoch [55/100] | Train Loss: 0.0073 | Train Acc: 1.0000\n",
      "Test Loss: 1.3449 | Test Acc: 0.6422\n",
      "Epoch 55 took 4.52 seconds\n",
      "Epoch [56/100] | Train Loss: 0.0073 | Train Acc: 1.0000\n",
      "Test Loss: 1.4725 | Test Acc: 0.6235\n",
      "Epoch 56 took 4.52 seconds\n",
      "Epoch [57/100] | Train Loss: 0.0069 | Train Acc: 1.0000\n",
      "Test Loss: 1.3457 | Test Acc: 0.6408\n",
      "Epoch 57 took 4.54 seconds\n",
      "Epoch [58/100] | Train Loss: 0.0062 | Train Acc: 1.0000\n",
      "Test Loss: 1.3114 | Test Acc: 0.6469\n",
      "Epoch 58 took 4.54 seconds\n",
      "Epoch [59/100] | Train Loss: 0.0065 | Train Acc: 1.0000\n",
      "Test Loss: 1.4405 | Test Acc: 0.6358\n",
      "Epoch 59 took 4.54 seconds\n",
      "Epoch [60/100] | Train Loss: 0.0061 | Train Acc: 1.0000\n",
      "Test Loss: 1.3636 | Test Acc: 0.6446\n",
      "Epoch 60 took 4.55 seconds\n",
      "Epoch [61/100] | Train Loss: 0.0058 | Train Acc: 1.0000\n",
      "Test Loss: 1.3765 | Test Acc: 0.6443\n",
      "Epoch 61 took 4.53 seconds\n",
      "Epoch [62/100] | Train Loss: 0.0067 | Train Acc: 0.9998\n",
      "Test Loss: 1.3310 | Test Acc: 0.6444\n",
      "Epoch 62 took 4.52 seconds\n",
      "Epoch [63/100] | Train Loss: 0.0058 | Train Acc: 1.0000\n",
      "Test Loss: 1.3807 | Test Acc: 0.6414\n",
      "Epoch 63 took 4.55 seconds\n",
      "Epoch [64/100] | Train Loss: 0.0052 | Train Acc: 1.0000\n",
      "Test Loss: 1.3630 | Test Acc: 0.6417\n",
      "Epoch 64 took 4.57 seconds\n",
      "Epoch [65/100] | Train Loss: 0.0055 | Train Acc: 1.0000\n",
      "Test Loss: 1.4075 | Test Acc: 0.6400\n",
      "Epoch 65 took 4.53 seconds\n",
      "Epoch [66/100] | Train Loss: 0.0052 | Train Acc: 1.0000\n",
      "Test Loss: 1.3391 | Test Acc: 0.6478\n",
      "Epoch 66 took 4.52 seconds\n",
      "Epoch [67/100] | Train Loss: 0.0052 | Train Acc: 1.0000\n",
      "Test Loss: 1.4625 | Test Acc: 0.6289\n",
      "Epoch 67 took 4.53 seconds\n",
      "Epoch [68/100] | Train Loss: 0.0050 | Train Acc: 1.0000\n",
      "Test Loss: 1.3620 | Test Acc: 0.6441\n",
      "Epoch 68 took 4.53 seconds\n",
      "Epoch [69/100] | Train Loss: 0.0049 | Train Acc: 1.0000\n",
      "Test Loss: 1.4042 | Test Acc: 0.6430\n",
      "Epoch 69 took 4.54 seconds\n",
      "Epoch [70/100] | Train Loss: 0.0048 | Train Acc: 1.0000\n",
      "Test Loss: 1.4427 | Test Acc: 0.6332\n",
      "Epoch 70 took 4.52 seconds\n",
      "Epoch [71/100] | Train Loss: 0.0049 | Train Acc: 1.0000\n",
      "Test Loss: 1.4009 | Test Acc: 0.6415\n",
      "Epoch 71 took 4.54 seconds\n",
      "Epoch [72/100] | Train Loss: 0.0046 | Train Acc: 1.0000\n",
      "Test Loss: 1.4207 | Test Acc: 0.6368\n",
      "Epoch 72 took 4.56 seconds\n",
      "Epoch [73/100] | Train Loss: 0.0044 | Train Acc: 1.0000\n",
      "Test Loss: 1.4269 | Test Acc: 0.6389\n",
      "Epoch 73 took 4.56 seconds\n",
      "Epoch [74/100] | Train Loss: 0.0044 | Train Acc: 1.0000\n",
      "Test Loss: 1.4188 | Test Acc: 0.6410\n",
      "Epoch 74 took 4.54 seconds\n",
      "Epoch [75/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.3661 | Test Acc: 0.6481\n",
      "Epoch 75 took 4.53 seconds\n",
      "Epoch [76/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.3524 | Test Acc: 0.6472\n",
      "Epoch 76 took 4.51 seconds\n",
      "Epoch [77/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.3660 | Test Acc: 0.6457\n",
      "Epoch 77 took 4.54 seconds\n",
      "Epoch [78/100] | Train Loss: 0.0041 | Train Acc: 1.0000\n",
      "Test Loss: 1.3832 | Test Acc: 0.6414\n",
      "Epoch 78 took 4.54 seconds\n",
      "Epoch [79/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.3965 | Test Acc: 0.6431\n",
      "Epoch 79 took 4.51 seconds\n",
      "Epoch [80/100] | Train Loss: 0.0040 | Train Acc: 1.0000\n",
      "Test Loss: 1.4026 | Test Acc: 0.6435\n",
      "Epoch 80 took 4.54 seconds\n",
      "Epoch [81/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.3855 | Test Acc: 0.6445\n",
      "Epoch 81 took 4.52 seconds\n",
      "Epoch [82/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.3797 | Test Acc: 0.6424\n",
      "Epoch 82 took 4.54 seconds\n",
      "Epoch [83/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.4030 | Test Acc: 0.6428\n",
      "Epoch 83 took 4.51 seconds\n",
      "Epoch [84/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.3985 | Test Acc: 0.6425\n",
      "Epoch 84 took 4.51 seconds\n",
      "Epoch [85/100] | Train Loss: 0.0036 | Train Acc: 1.0000\n",
      "Test Loss: 1.4499 | Test Acc: 0.6368\n",
      "Epoch 85 took 4.54 seconds\n",
      "Epoch [86/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.3512 | Test Acc: 0.6451\n",
      "Epoch 86 took 4.53 seconds\n",
      "Epoch [87/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4003 | Test Acc: 0.6430\n",
      "Epoch 87 took 4.50 seconds\n",
      "Epoch [88/100] | Train Loss: 0.0036 | Train Acc: 1.0000\n",
      "Test Loss: 1.3883 | Test Acc: 0.6442\n",
      "Epoch 88 took 4.53 seconds\n",
      "Epoch [89/100] | Train Loss: 0.0034 | Train Acc: 1.0000\n",
      "Test Loss: 1.4346 | Test Acc: 0.6401\n",
      "Epoch 89 took 4.52 seconds\n",
      "Epoch [90/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.4692 | Test Acc: 0.6389\n",
      "Epoch 90 took 4.59 seconds\n",
      "Epoch [91/100] | Train Loss: 0.0034 | Train Acc: 1.0000\n",
      "Test Loss: 1.3923 | Test Acc: 0.6448\n",
      "Epoch 91 took 4.56 seconds\n",
      "Epoch [92/100] | Train Loss: 0.0034 | Train Acc: 1.0000\n",
      "Test Loss: 1.4741 | Test Acc: 0.6360\n",
      "Epoch 92 took 4.53 seconds\n",
      "Epoch [93/100] | Train Loss: 0.0034 | Train Acc: 1.0000\n",
      "Test Loss: 1.4177 | Test Acc: 0.6412\n",
      "Epoch 93 took 4.54 seconds\n",
      "Epoch [94/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.3924 | Test Acc: 0.6456\n",
      "Epoch 94 took 4.53 seconds\n",
      "Epoch [95/100] | Train Loss: 0.0033 | Train Acc: 1.0000\n",
      "Test Loss: 1.4121 | Test Acc: 0.6418\n",
      "Epoch 95 took 4.55 seconds\n",
      "Epoch [96/100] | Train Loss: 0.0033 | Train Acc: 1.0000\n",
      "Test Loss: 1.4374 | Test Acc: 0.6390\n",
      "Epoch 96 took 4.55 seconds\n",
      "Epoch [97/100] | Train Loss: 0.0033 | Train Acc: 1.0000\n",
      "Test Loss: 1.4903 | Test Acc: 0.6344\n",
      "Epoch 97 took 4.57 seconds\n",
      "Epoch [98/100] | Train Loss: 0.0032 | Train Acc: 1.0000\n",
      "Test Loss: 1.3884 | Test Acc: 0.6416\n",
      "Epoch 98 took 4.51 seconds\n",
      "Epoch [99/100] | Train Loss: 0.0034 | Train Acc: 1.0000\n",
      "Test Loss: 1.4599 | Test Acc: 0.6392\n",
      "Epoch 99 took 4.53 seconds\n",
      "Epoch [100/100] | Train Loss: 0.0033 | Train Acc: 1.0000\n",
      "Test Loss: 1.4197 | Test Acc: 0.6390\n",
      "Epoch 100 took 4.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 11:03:55,267 - INFO - Train accuracy 1.0, Train Loss 0.0037437779781389602\n",
      "2025-02-06 11:03:55,268 - INFO - Test accuracy 0.63904, Test Loss 1.419813417658514\n",
      "2025-02-06 11:03:55,278 - INFO - Training model 1 took 456.08333253860474 seconds\n",
      "2025-02-06 11:03:55,295 - INFO - --------------------------------------------------\n",
      "2025-02-06 11:03:55,295 - INFO - Training model 2: Train size 25000, Test size 25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 2.2485 | Train Acc: 0.1440\n",
      "Test Loss: 2.0968 | Test Acc: 0.2458\n",
      "Epoch 1 took 4.78 seconds\n",
      "Epoch [2/100] | Train Loss: 1.9579 | Train Acc: 0.2927\n",
      "Test Loss: 1.8407 | Test Acc: 0.3178\n",
      "Epoch 2 took 4.55 seconds\n",
      "Epoch [3/100] | Train Loss: 1.7865 | Train Acc: 0.3446\n",
      "Test Loss: 1.7790 | Test Acc: 0.3464\n",
      "Epoch 3 took 4.57 seconds\n",
      "Epoch [4/100] | Train Loss: 1.6700 | Train Acc: 0.3875\n",
      "Test Loss: 1.6581 | Test Acc: 0.3898\n",
      "Epoch 4 took 4.52 seconds\n",
      "Epoch [5/100] | Train Loss: 1.5611 | Train Acc: 0.4328\n",
      "Test Loss: 1.6060 | Test Acc: 0.4046\n",
      "Epoch 5 took 4.52 seconds\n",
      "Epoch [6/100] | Train Loss: 1.4670 | Train Acc: 0.4691\n",
      "Test Loss: 1.4764 | Test Acc: 0.4604\n",
      "Epoch 6 took 4.54 seconds\n",
      "Epoch [7/100] | Train Loss: 1.3832 | Train Acc: 0.5008\n",
      "Test Loss: 1.8152 | Test Acc: 0.3603\n",
      "Epoch 7 took 4.53 seconds\n",
      "Epoch [8/100] | Train Loss: 1.3155 | Train Acc: 0.5279\n",
      "Test Loss: 1.4083 | Test Acc: 0.4900\n",
      "Epoch 8 took 4.56 seconds\n",
      "Epoch [9/100] | Train Loss: 1.2474 | Train Acc: 0.5506\n",
      "Test Loss: 1.6307 | Test Acc: 0.4111\n",
      "Epoch 9 took 4.57 seconds\n",
      "Epoch [10/100] | Train Loss: 1.1990 | Train Acc: 0.5710\n",
      "Test Loss: 1.6879 | Test Acc: 0.4536\n",
      "Epoch 10 took 4.54 seconds\n",
      "Epoch [11/100] | Train Loss: 1.1348 | Train Acc: 0.5965\n",
      "Test Loss: 1.6417 | Test Acc: 0.4354\n",
      "Epoch 11 took 4.55 seconds\n",
      "Epoch [12/100] | Train Loss: 1.0884 | Train Acc: 0.6151\n",
      "Test Loss: 1.3505 | Test Acc: 0.5213\n",
      "Epoch 12 took 4.51 seconds\n",
      "Epoch [13/100] | Train Loss: 1.0363 | Train Acc: 0.6306\n",
      "Test Loss: 1.1787 | Test Acc: 0.5756\n",
      "Epoch 13 took 4.55 seconds\n",
      "Epoch [14/100] | Train Loss: 0.9916 | Train Acc: 0.6502\n",
      "Test Loss: 1.2093 | Test Acc: 0.5712\n",
      "Epoch 14 took 4.54 seconds\n",
      "Epoch [15/100] | Train Loss: 0.9475 | Train Acc: 0.6653\n",
      "Test Loss: 1.2052 | Test Acc: 0.5726\n",
      "Epoch 15 took 4.54 seconds\n",
      "Epoch [16/100] | Train Loss: 0.8998 | Train Acc: 0.6835\n",
      "Test Loss: 1.4521 | Test Acc: 0.5275\n",
      "Epoch 16 took 4.55 seconds\n",
      "Epoch [17/100] | Train Loss: 0.8570 | Train Acc: 0.7014\n",
      "Test Loss: 1.3434 | Test Acc: 0.5432\n",
      "Epoch 17 took 4.51 seconds\n",
      "Epoch [18/100] | Train Loss: 0.8148 | Train Acc: 0.7158\n",
      "Test Loss: 2.1300 | Test Acc: 0.4224\n",
      "Epoch 18 took 4.52 seconds\n",
      "Epoch [19/100] | Train Loss: 0.7706 | Train Acc: 0.7311\n",
      "Test Loss: 1.6122 | Test Acc: 0.4962\n",
      "Epoch 19 took 4.53 seconds\n",
      "Epoch [20/100] | Train Loss: 0.7238 | Train Acc: 0.7497\n",
      "Test Loss: 2.1351 | Test Acc: 0.4223\n",
      "Epoch 20 took 4.50 seconds\n",
      "Epoch [21/100] | Train Loss: 0.6731 | Train Acc: 0.7695\n",
      "Test Loss: 2.0684 | Test Acc: 0.4960\n",
      "Epoch 21 took 4.54 seconds\n",
      "Epoch [22/100] | Train Loss: 0.6314 | Train Acc: 0.7862\n",
      "Test Loss: 1.2308 | Test Acc: 0.5720\n",
      "Epoch 22 took 4.52 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5787 | Train Acc: 0.8062\n",
      "Test Loss: 2.7365 | Test Acc: 0.3709\n",
      "Epoch 23 took 4.52 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5356 | Train Acc: 0.8217\n",
      "Test Loss: 1.4241 | Test Acc: 0.5587\n",
      "Epoch 24 took 4.53 seconds\n",
      "Epoch [25/100] | Train Loss: 0.5076 | Train Acc: 0.8328\n",
      "Test Loss: 4.1011 | Test Acc: 0.3343\n",
      "Epoch 25 took 4.53 seconds\n",
      "Epoch [26/100] | Train Loss: 0.4472 | Train Acc: 0.8574\n",
      "Test Loss: 1.7520 | Test Acc: 0.5240\n",
      "Epoch 26 took 4.54 seconds\n",
      "Epoch [27/100] | Train Loss: 0.3897 | Train Acc: 0.8783\n",
      "Test Loss: 2.5131 | Test Acc: 0.4320\n",
      "Epoch 27 took 4.52 seconds\n",
      "Epoch [28/100] | Train Loss: 0.3503 | Train Acc: 0.8917\n",
      "Test Loss: 1.8810 | Test Acc: 0.4906\n",
      "Epoch 28 took 4.52 seconds\n",
      "Epoch [29/100] | Train Loss: 0.3018 | Train Acc: 0.9117\n",
      "Test Loss: 1.6194 | Test Acc: 0.5350\n",
      "Epoch 29 took 4.53 seconds\n",
      "Epoch [30/100] | Train Loss: 0.2629 | Train Acc: 0.9269\n",
      "Test Loss: 1.4915 | Test Acc: 0.5840\n",
      "Epoch 30 took 4.52 seconds\n",
      "Epoch [31/100] | Train Loss: 0.2246 | Train Acc: 0.9398\n",
      "Test Loss: 2.0550 | Test Acc: 0.4773\n",
      "Epoch 31 took 4.55 seconds\n",
      "Epoch [32/100] | Train Loss: 0.1702 | Train Acc: 0.9618\n",
      "Test Loss: 1.5825 | Test Acc: 0.5447\n",
      "Epoch 32 took 4.51 seconds\n",
      "Epoch [33/100] | Train Loss: 0.1637 | Train Acc: 0.9605\n",
      "Test Loss: 1.6903 | Test Acc: 0.5653\n",
      "Epoch 33 took 4.54 seconds\n",
      "Epoch [34/100] | Train Loss: 0.1007 | Train Acc: 0.9843\n",
      "Test Loss: 2.2491 | Test Acc: 0.4813\n",
      "Epoch 34 took 4.52 seconds\n",
      "Epoch [35/100] | Train Loss: 0.0909 | Train Acc: 0.9856\n",
      "Test Loss: 1.4978 | Test Acc: 0.5903\n",
      "Epoch 35 took 4.55 seconds\n",
      "Epoch [36/100] | Train Loss: 0.0567 | Train Acc: 0.9954\n",
      "Test Loss: 1.4069 | Test Acc: 0.6102\n",
      "Epoch 36 took 4.50 seconds\n",
      "Epoch [37/100] | Train Loss: 0.0414 | Train Acc: 0.9977\n",
      "Test Loss: 1.3211 | Test Acc: 0.6276\n",
      "Epoch 37 took 4.52 seconds\n",
      "Epoch [38/100] | Train Loss: 0.0344 | Train Acc: 0.9982\n",
      "Test Loss: 1.3183 | Test Acc: 0.6204\n",
      "Epoch 38 took 4.52 seconds\n",
      "Epoch [39/100] | Train Loss: 0.0276 | Train Acc: 0.9990\n",
      "Test Loss: 1.3688 | Test Acc: 0.6194\n",
      "Epoch 39 took 4.53 seconds\n",
      "Epoch [40/100] | Train Loss: 0.0231 | Train Acc: 0.9995\n",
      "Test Loss: 1.3124 | Test Acc: 0.6321\n",
      "Epoch 40 took 4.52 seconds\n",
      "Epoch [41/100] | Train Loss: 0.0208 | Train Acc: 0.9996\n",
      "Test Loss: 1.3330 | Test Acc: 0.6302\n",
      "Epoch 41 took 4.51 seconds\n",
      "Epoch [42/100] | Train Loss: 0.0179 | Train Acc: 0.9997\n",
      "Test Loss: 1.3240 | Test Acc: 0.6311\n",
      "Epoch 42 took 4.53 seconds\n",
      "Epoch [43/100] | Train Loss: 0.0157 | Train Acc: 0.9998\n",
      "Test Loss: 1.3509 | Test Acc: 0.6276\n",
      "Epoch 43 took 4.52 seconds\n",
      "Epoch [44/100] | Train Loss: 0.0148 | Train Acc: 0.9998\n",
      "Test Loss: 1.3656 | Test Acc: 0.6298\n",
      "Epoch 44 took 4.53 seconds\n",
      "Epoch [45/100] | Train Loss: 0.0132 | Train Acc: 0.9999\n",
      "Test Loss: 1.3656 | Test Acc: 0.6251\n",
      "Epoch 45 took 4.56 seconds\n",
      "Epoch [46/100] | Train Loss: 0.0132 | Train Acc: 0.9999\n",
      "Test Loss: 1.3552 | Test Acc: 0.6314\n",
      "Epoch 46 took 4.50 seconds\n",
      "Epoch [47/100] | Train Loss: 0.0118 | Train Acc: 0.9999\n",
      "Test Loss: 1.4897 | Test Acc: 0.6105\n",
      "Epoch 47 took 4.53 seconds\n",
      "Epoch [48/100] | Train Loss: 0.0106 | Train Acc: 0.9999\n",
      "Test Loss: 1.3819 | Test Acc: 0.6241\n",
      "Epoch 48 took 4.54 seconds\n",
      "Epoch [49/100] | Train Loss: 0.0101 | Train Acc: 0.9999\n",
      "Test Loss: 1.3389 | Test Acc: 0.6337\n",
      "Epoch 49 took 4.53 seconds\n",
      "Epoch [50/100] | Train Loss: 0.0091 | Train Acc: 0.9999\n",
      "Test Loss: 1.4549 | Test Acc: 0.6191\n",
      "Epoch 50 took 4.53 seconds\n",
      "Epoch [51/100] | Train Loss: 0.0093 | Train Acc: 0.9999\n",
      "Test Loss: 1.4102 | Test Acc: 0.6273\n",
      "Epoch 51 took 4.51 seconds\n",
      "Epoch [52/100] | Train Loss: 0.0086 | Train Acc: 0.9999\n",
      "Test Loss: 1.3681 | Test Acc: 0.6312\n",
      "Epoch 52 took 4.53 seconds\n",
      "Epoch [53/100] | Train Loss: 0.0087 | Train Acc: 1.0000\n",
      "Test Loss: 1.4048 | Test Acc: 0.6256\n",
      "Epoch 53 took 4.56 seconds\n",
      "Epoch [54/100] | Train Loss: 0.0086 | Train Acc: 0.9999\n",
      "Test Loss: 1.3826 | Test Acc: 0.6317\n",
      "Epoch 54 took 4.51 seconds\n",
      "Epoch [55/100] | Train Loss: 0.0085 | Train Acc: 0.9998\n",
      "Test Loss: 1.4077 | Test Acc: 0.6237\n",
      "Epoch 55 took 4.52 seconds\n",
      "Epoch [56/100] | Train Loss: 0.0080 | Train Acc: 1.0000\n",
      "Test Loss: 1.3720 | Test Acc: 0.6317\n",
      "Epoch 56 took 4.53 seconds\n",
      "Epoch [57/100] | Train Loss: 0.0073 | Train Acc: 0.9999\n",
      "Test Loss: 1.4541 | Test Acc: 0.6253\n",
      "Epoch 57 took 4.52 seconds\n",
      "Epoch [58/100] | Train Loss: 0.0070 | Train Acc: 0.9999\n",
      "Test Loss: 1.3913 | Test Acc: 0.6305\n",
      "Epoch 58 took 4.55 seconds\n",
      "Epoch [59/100] | Train Loss: 0.0070 | Train Acc: 1.0000\n",
      "Test Loss: 1.4462 | Test Acc: 0.6289\n",
      "Epoch 59 took 4.52 seconds\n",
      "Epoch [60/100] | Train Loss: 0.0063 | Train Acc: 1.0000\n",
      "Test Loss: 1.4025 | Test Acc: 0.6271\n",
      "Epoch 60 took 4.55 seconds\n",
      "Epoch [61/100] | Train Loss: 0.0062 | Train Acc: 1.0000\n",
      "Test Loss: 1.3951 | Test Acc: 0.6291\n",
      "Epoch 61 took 4.54 seconds\n",
      "Epoch [62/100] | Train Loss: 0.0060 | Train Acc: 1.0000\n",
      "Test Loss: 1.4445 | Test Acc: 0.6280\n",
      "Epoch 62 took 4.54 seconds\n",
      "Epoch [63/100] | Train Loss: 0.0057 | Train Acc: 1.0000\n",
      "Test Loss: 1.4234 | Test Acc: 0.6277\n",
      "Epoch 63 took 4.55 seconds\n",
      "Epoch [64/100] | Train Loss: 0.0055 | Train Acc: 1.0000\n",
      "Test Loss: 1.4171 | Test Acc: 0.6298\n",
      "Epoch 64 took 4.53 seconds\n",
      "Epoch [65/100] | Train Loss: 0.0057 | Train Acc: 1.0000\n",
      "Test Loss: 1.4448 | Test Acc: 0.6234\n",
      "Epoch 65 took 4.53 seconds\n",
      "Epoch [66/100] | Train Loss: 0.0056 | Train Acc: 0.9999\n",
      "Test Loss: 1.4298 | Test Acc: 0.6281\n",
      "Epoch 66 took 4.57 seconds\n",
      "Epoch [67/100] | Train Loss: 0.0051 | Train Acc: 1.0000\n",
      "Test Loss: 1.4647 | Test Acc: 0.6261\n",
      "Epoch 67 took 4.51 seconds\n",
      "Epoch [68/100] | Train Loss: 0.0050 | Train Acc: 1.0000\n",
      "Test Loss: 1.4235 | Test Acc: 0.6256\n",
      "Epoch 68 took 4.51 seconds\n",
      "Epoch [69/100] | Train Loss: 0.0050 | Train Acc: 1.0000\n",
      "Test Loss: 1.4799 | Test Acc: 0.6252\n",
      "Epoch 69 took 4.54 seconds\n",
      "Epoch [70/100] | Train Loss: 0.0049 | Train Acc: 1.0000\n",
      "Test Loss: 1.4685 | Test Acc: 0.6225\n",
      "Epoch 70 took 4.52 seconds\n",
      "Epoch [71/100] | Train Loss: 0.0048 | Train Acc: 1.0000\n",
      "Test Loss: 1.4456 | Test Acc: 0.6300\n",
      "Epoch 71 took 4.52 seconds\n",
      "Epoch [72/100] | Train Loss: 0.0046 | Train Acc: 1.0000\n",
      "Test Loss: 1.4257 | Test Acc: 0.6303\n",
      "Epoch 72 took 4.50 seconds\n",
      "Epoch [73/100] | Train Loss: 0.0045 | Train Acc: 1.0000\n",
      "Test Loss: 1.4769 | Test Acc: 0.6252\n",
      "Epoch 73 took 4.53 seconds\n",
      "Epoch [74/100] | Train Loss: 0.0045 | Train Acc: 1.0000\n",
      "Test Loss: 1.4276 | Test Acc: 0.6292\n",
      "Epoch 74 took 4.56 seconds\n",
      "Epoch [75/100] | Train Loss: 0.0045 | Train Acc: 1.0000\n",
      "Test Loss: 1.4627 | Test Acc: 0.6269\n",
      "Epoch 75 took 4.53 seconds\n",
      "Epoch [76/100] | Train Loss: 0.0045 | Train Acc: 1.0000\n",
      "Test Loss: 1.5154 | Test Acc: 0.6211\n",
      "Epoch 76 took 4.53 seconds\n",
      "Epoch [77/100] | Train Loss: 0.0043 | Train Acc: 1.0000\n",
      "Test Loss: 1.5846 | Test Acc: 0.6126\n",
      "Epoch 77 took 4.54 seconds\n",
      "Epoch [78/100] | Train Loss: 0.0042 | Train Acc: 1.0000\n",
      "Test Loss: 1.4832 | Test Acc: 0.6246\n",
      "Epoch 78 took 4.55 seconds\n",
      "Epoch [79/100] | Train Loss: 0.0044 | Train Acc: 1.0000\n",
      "Test Loss: 1.4824 | Test Acc: 0.6229\n",
      "Epoch 79 took 4.52 seconds\n",
      "Epoch [80/100] | Train Loss: 0.0040 | Train Acc: 1.0000\n",
      "Test Loss: 1.4569 | Test Acc: 0.6290\n",
      "Epoch 80 took 4.53 seconds\n",
      "Epoch [81/100] | Train Loss: 0.0041 | Train Acc: 1.0000\n",
      "Test Loss: 1.4676 | Test Acc: 0.6282\n",
      "Epoch 81 took 4.56 seconds\n",
      "Epoch [82/100] | Train Loss: 0.0041 | Train Acc: 1.0000\n",
      "Test Loss: 1.4655 | Test Acc: 0.6256\n",
      "Epoch 82 took 4.50 seconds\n",
      "Epoch [83/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.4947 | Test Acc: 0.6230\n",
      "Epoch 83 took 4.53 seconds\n",
      "Epoch [84/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.4987 | Test Acc: 0.6229\n",
      "Epoch 84 took 4.53 seconds\n",
      "Epoch [85/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4612 | Test Acc: 0.6287\n",
      "Epoch 85 took 4.53 seconds\n",
      "Epoch [86/100] | Train Loss: 0.0041 | Train Acc: 1.0000\n",
      "Test Loss: 1.4812 | Test Acc: 0.6241\n",
      "Epoch 86 took 4.52 seconds\n",
      "Epoch [87/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4837 | Test Acc: 0.6205\n",
      "Epoch 87 took 4.51 seconds\n",
      "Epoch [88/100] | Train Loss: 0.0039 | Train Acc: 1.0000\n",
      "Test Loss: 1.4884 | Test Acc: 0.6231\n",
      "Epoch 88 took 4.52 seconds\n",
      "Epoch [89/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4517 | Test Acc: 0.6273\n",
      "Epoch 89 took 4.50 seconds\n",
      "Epoch [90/100] | Train Loss: 0.0038 | Train Acc: 1.0000\n",
      "Test Loss: 1.4729 | Test Acc: 0.6243\n",
      "Epoch 90 took 4.55 seconds\n",
      "Epoch [91/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.4859 | Test Acc: 0.6212\n",
      "Epoch 91 took 4.51 seconds\n",
      "Epoch [92/100] | Train Loss: 0.0037 | Train Acc: 1.0000\n",
      "Test Loss: 1.5626 | Test Acc: 0.6179\n",
      "Epoch 92 took 4.57 seconds\n",
      "Epoch [93/100] | Train Loss: 0.0034 | Train Acc: 1.0000\n",
      "Test Loss: 1.4687 | Test Acc: 0.6268\n",
      "Epoch 93 took 4.52 seconds\n",
      "Epoch [94/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.5281 | Test Acc: 0.6193\n",
      "Epoch 94 took 4.53 seconds\n",
      "Epoch [95/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.5146 | Test Acc: 0.6233\n",
      "Epoch 95 took 4.54 seconds\n",
      "Epoch [96/100] | Train Loss: 0.0033 | Train Acc: 1.0000\n",
      "Test Loss: 1.5121 | Test Acc: 0.6236\n",
      "Epoch 96 took 4.52 seconds\n",
      "Epoch [97/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.5055 | Test Acc: 0.6263\n",
      "Epoch 97 took 4.54 seconds\n",
      "Epoch [98/100] | Train Loss: 0.0033 | Train Acc: 1.0000\n",
      "Test Loss: 1.4381 | Test Acc: 0.6311\n",
      "Epoch 98 took 4.55 seconds\n",
      "Epoch [99/100] | Train Loss: 0.0035 | Train Acc: 1.0000\n",
      "Test Loss: 1.4787 | Test Acc: 0.6244\n",
      "Epoch 99 took 4.54 seconds\n",
      "Epoch [100/100] | Train Loss: 0.0036 | Train Acc: 1.0000\n",
      "Test Loss: 1.4999 | Test Acc: 0.6269\n",
      "Epoch 100 took 4.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 11:11:30,969 - INFO - Train accuracy 1.0, Train Loss 0.0027838589371733218\n",
      "2025-02-06 11:11:30,970 - INFO - Test accuracy 0.62692, Test Loss 1.5007508044340172\n",
      "2025-02-06 11:11:30,980 - INFO - Training model 2 took 455.6854817867279 seconds\n"
     ]
    }
   ],
   "source": [
    "data_splits = [target_data_split, ref_data_split, ref_paired_data_split]\n",
    "memberships = np.array([target_membership, ref_membership, ref_paired_membership]) # size: 2N+1 * len(dataset)\n",
    "models_list = train_models(\n",
    "    log_dir, dataset, data_splits, memberships, configs, logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_list, memberships = load_models(log_dir, dataset, 3, configs, logger)\n",
    "# target_membership, ref_membership, ref_paired_membership = memberships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring $p$\n",
    "We have imported the DUCI module using: `from modules.duci import DUCI`. In DUCI, the standard MIA is executed first, so we need to set up the MIA before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the population dataset used in MIA\n",
    "population = Subset(\n",
    "    population,\n",
    "    np.random.choice(\n",
    "        len(population),\n",
    "        configs[\"audit\"].get(\"population_size\", len(population)),\n",
    "        replace=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the victim model and the reference model to generate signals (softmax outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 11:11:31,382 - INFO - Computing signals for all models.\n",
      "Computing softmax: 100%|| 1/1 [00:00<00:00, 15.19it/s]\n",
      "Computing softmax: 100%|| 1/1 [00:00<00:00, 50.74it/s]\n",
      "Computing softmax: 100%|| 1/1 [00:00<00:00, 50.73it/s]\n",
      "2025-02-06 11:11:31,536 - INFO - Signals saved to disk.\n",
      "2025-02-06 11:11:32,651 - INFO - Computing signals for all models.\n",
      "Computing softmax: 100%|| 2/2 [00:00<00:00,  5.43it/s]\n",
      "Computing softmax: 100%|| 2/2 [00:00<00:00,  5.58it/s]\n",
      "Computing softmax: 100%|| 2/2 [00:00<00:00,  5.56it/s]\n",
      "2025-02-06 11:11:33,777 - INFO - Signals saved to disk.\n",
      "2025-02-06 11:11:33,785 - INFO - Preparing signals took 2.68006 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline_time = time.time()\n",
    "auditing_dataset = Subset(dataset, target_indices)\n",
    "auditing_membership = np.array([target_membership[target_indices], ref_membership[target_indices], ref_paired_membership[target_indices]]).astype(bool) # size: 2 * len(auditing_dataset)   \n",
    "signals = get_model_signals(models_list, auditing_dataset, configs, logger) # num_samples * num_models\n",
    "auditing_membership = auditing_membership.T\n",
    "assert signals.shape == auditing_membership.shape, f\"signals or auditing_membership has incorrect shape (num_samples * num_models): {signals.shape} vs {auditing_membership.shape}\"\n",
    "population_signals = get_model_signals(\n",
    "    models_list, population, configs, logger, is_population=True\n",
    ")\n",
    "logger.info(\"Preparing signals took %0.5f seconds\", time.time() - baseline_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.5, 0.5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auditing_membership[:, 0].mean(), auditing_membership[:, 1].mean(), auditing_membership[:, 2].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform DUCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 11:11:33,809 - INFO - Initiate DUCI for target models: 0\n",
      "2025-02-06 11:11:33,812 - INFO - Collecting membership prediction for each sample in the target dataset on target models and reference models.\n",
      "2025-02-06 11:11:33,813 - INFO - Predicting the proportion of dataset usage on target models.\n",
      "2025-02-06 11:11:33,814 - INFO - Args for MIA attack: {'attack': 'RMIA', 'dataset': 'cifar10', 'model': 'wrn28-2', 'offline_a': 0.3}\n",
      "2025-02-06 11:11:33,814 - INFO - Running RMIA attack on target model 0 with offline_a=0.3\n",
      "2025-02-06 11:11:33,829 - INFO - Collect membership prediction for target dataset on target model 0 costs 0.0 seconds\n",
      "2025-02-06 11:11:33,830 - INFO - Args for MIA attack: {'attack': 'RMIA', 'dataset': 'cifar10', 'model': 'wrn28-2', 'offline_a': 0.3}\n",
      "2025-02-06 11:11:33,831 - INFO - Running RMIA attack on target model 1 with offline_a=0.3\n",
      "2025-02-06 11:11:33,843 - INFO - Args for MIA attack: {'attack': 'RMIA', 'dataset': 'cifar10', 'model': 'wrn28-2', 'offline_a': 0.3}\n",
      "2025-02-06 11:11:33,844 - INFO - Running RMIA attack on target model 2 with offline_a=0.3\n",
      "2025-02-06 11:11:33,861 - INFO - Best threshold = 0.5601 (Maximize TPR - FPR) = 0.964 - 0.322\n",
      "2025-02-06 11:11:33,862 - INFO - True proportion 0.4, True TPR: 0.89, True FPR: 0.3466666666666667\n",
      "2025-02-06 11:11:33,863 - INFO - DUCI prediction: 0.37694704049844235; Direct Aggregation: 0.564\n",
      "2025-02-06 11:11:33,863 - INFO - Absolute Error $| \\hat{p} - p|$: Debiased Agg MIA = 0.0231\n",
      "2025-02-06 11:11:33,864 - INFO - DUCI 0.1 seconds\n",
      "2025-02-06 11:11:33,865 - INFO - Average prediction errors: 0.023052959501557668\n",
      "2025-02-06 11:11:33,866 - INFO - All prediction errors: [0.023052959501557668]\n",
      "2025-02-06 11:11:33,866 - INFO - Prediction details: DUCI predictions: [0.37694704049844235], True proportions: [0.4]\n"
     ]
    }
   ],
   "source": [
    "baseline_time = time.time()\n",
    "target_model_idx = 0\n",
    "ref_model_indices = [1, 2]\n",
    "\n",
    "logger.info(f\"Initiate DUCI for target models: {target_model_idx}\")\n",
    "# args = {\n",
    "#     \"attack\": \"RMIA\",\n",
    "#     \"dataset\": configs[\"data\"][\"dataset\"], # TODO: have DUCI config\n",
    "#     \"model\": configs[\"train\"][\"model_name\"],\n",
    "#     \"offline_a\": None\n",
    "# }\n",
    "args = {\n",
    "    \"attack\": \"RMIA\",\n",
    "    \"dataset\": configs[\"data\"][\"dataset\"], # TODO: have DUCI config\n",
    "    \"model\": configs[\"train\"][\"model_name\"],\n",
    "    \"offline_a\": 0.3\n",
    "}\n",
    "DUCI_instance = DUCI(logger, args)\n",
    "\n",
    "logger.info(\"Collecting membership prediction for each sample in the target dataset on target models and reference models.\")\n",
    "logger.info(\"Predicting the proportion of dataset usage on target models.\")\n",
    "\n",
    "duci_preds, true_proportions, errors = DUCI_instance.pred_proportions(\n",
    "    [target_model_idx], \n",
    "    [ref_model_indices], \n",
    "    signals,\n",
    "    population_signals,\n",
    "    auditing_membership,\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    \"DUCI %0.1f seconds\", time.time() - baseline_time\n",
    ")\n",
    "logger.info(f\"Average prediction errors: {np.mean(errors)}\")\n",
    "logger.info(f\"All prediction errors: {errors}\")\n",
    "logger.info(f\"Prediction details: DUCI predictions: {duci_preds}, True proportions: {true_proportions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the prediction and $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37694704049844235"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duci_preds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
